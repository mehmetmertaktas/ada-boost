{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JFVnPMMO0x4C"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "K7fYDihd7eEu"
   },
   "outputs": [],
   "source": [
    "MAX_DEPTH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_G0F1RBIJAdp"
   },
   "outputs": [],
   "source": [
    "X1, y1 = make_gaussian_quantiles(cov=2.,\n",
    "                                 n_samples=200, n_features=2,\n",
    "                                 n_classes=2, random_state=1)\n",
    "X2, y2 = make_gaussian_quantiles(mean=(3, 3), cov=1.5,\n",
    "                                 n_samples=300, n_features=2,\n",
    "                                 n_classes=2, random_state=1)\n",
    "X = np.concatenate((X1, X2))\n",
    "y = np.concatenate((y1, - y2 + 1))\n",
    "y[y == 0] = -1\n",
    "\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lzs3yJoU0x4J"
   },
   "outputs": [],
   "source": [
    "def sample(M, p):\n",
    "    \n",
    "    cum_p = np.cumsum(p)\n",
    "    cum_p = np.insert(cum_p, 0, 0)\n",
    "    \n",
    "    out = []\n",
    "    for j in range(M):\n",
    "        number = np.random.uniform()\n",
    "        for i in range(len(p)):\n",
    "            if cum_p[i] <= number < cum_p[i+1]:\n",
    "                out.append(i)\n",
    "                \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "csan2Z7M0x4J"
   },
   "outputs": [],
   "source": [
    "class MyAdaBoostClassifier():\n",
    "    \n",
    "    def __init__(self, n_estimators):\n",
    "        \n",
    "        self.n_estimators = n_estimators\n",
    "        self.base_estimator = DecisionTreeClassifier(random_state=0, \n",
    "                                                     max_depth=1)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.X_tr = X\n",
    "        self.y_tr = y\n",
    "        \n",
    "        N = len(y)\n",
    "        \n",
    "        self.h     = np.empty([self.n_estimators, N])\n",
    "        self.D     = np.empty([self.n_estimators + 1, N])\n",
    "        self.alpha = np.empty(self.n_estimators)\n",
    "        epsilon    = np.empty(self.n_estimators)\n",
    "        Z          = np.empty(self.n_estimators)\n",
    "        \n",
    "        self.D[0] = (1 / N) * np.ones(N)\n",
    "\n",
    "        for t in range(self.n_estimators):\n",
    "\n",
    "            ### step 1 ###\n",
    "            idx = sample(N, self.D[t])\n",
    "            self.base_estimator.fit(X[idx], y[idx])\n",
    "            self.h[t] = self.base_estimator.predict(X)\n",
    "\n",
    "            ### step 2 ###\n",
    "            idx = np.where(self.h[t] != y)\n",
    "            epsilon[t] = np.sum(self.D[t][idx])\n",
    "\n",
    "            ### step 3 ###\n",
    "            self.alpha[t] = 0.5 * np.log( (1 - epsilon[t]) / epsilon[t] )\n",
    "\n",
    "            ### step 4 ###\n",
    "            Z[t] = 2 * np.sqrt( (1 - epsilon[t]) * epsilon[t] )\n",
    "            self.D[t + 1] = ((self.D[t] / Z[t]) *\n",
    "                             np.exp(-self.alpha[t] * np.multiply(self.h[t], y)))\n",
    "            \n",
    "    def predict(self, X):\n",
    "\n",
    "        N = len(X)\n",
    "\n",
    "        F = np.empty(X.shape[0])\n",
    "        for t in range(self.n_estimators):\n",
    "\n",
    "            idx = sample(N, self.D[t])\n",
    "            self.base_estimator.fit(self.X_tr[idx], self.y_tr[idx])\n",
    "\n",
    "            F += np.multiply(self.alpha[t], self.base_estimator.predict(X))\n",
    "\n",
    "        return np.sign(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RCAtiNkN0x4L",
    "outputId": "e60ce53a-92ba-4db6-a689-2046acd60de7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracies\n",
      "==================\n",
      "\n",
      "Accuracy of sklearn.ensemble.AdaBoostClassifier is 0.81\n",
      "Accuracy of sklearn.tree.DecisionTreeClassifier is 0.55\n",
      "Accuracy of MyAdaBoostClassifier is 0.64\n"
     ]
    }
   ],
   "source": [
    "title = f'Testing accuracies'\n",
    "print(title)\n",
    "print('=' * len(title))\n",
    "print()\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "predicts = clf.predict(X_test)\n",
    "\n",
    "unique, counts = np.unique(predicts == y_test, return_counts=True)\n",
    "print(f'Accuracy of sklearn.ensemble.AdaBoostClassifier is '\\\n",
    "      f'{counts[1] / np.sum(counts):.2f}')\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=MAX_DEPTH)\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "predicts = clf.predict(X_test)\n",
    "\n",
    "unique, counts = np.unique(predicts == y_test, return_counts=True)\n",
    "print(f'Accuracy of sklearn.tree.DecisionTreeClassifier is '\\\n",
    "      f'{counts[1] / np.sum(counts):.2f}')\n",
    "\n",
    "clf = MyAdaBoostClassifier(n_estimators=100)\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "predicts = clf.predict(X_test)\n",
    "\n",
    "unique, counts = np.unique(predicts == y_test, return_counts=True)\n",
    "print(f'Accuracy of MyAdaBoostClassifier is {counts[1] / np.sum(counts):.2f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MyAdaBoostClassifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
